ğŸ“˜ README.md
markdown
# ğŸ§  Knowledge Assistant

A context-aware, memory-enabled Python assistant that answers questions using a custom document knowledge base. It supports persistent memory, intelligent fallback logic, and conversational follow-ups â€” making it ideal for internal knowledge retrieval, document Q&A, and smart assistants.

---

## ğŸš€ Features

- ğŸ” Vector search over document chunks
- ğŸ§  LLM-powered answers with memory context
- ğŸ’¾ Persistent memory across sessions
- ğŸ§ª Intelligent fallback using keyword matching
- ğŸ”„ Auto-generated follow-up questions
- ğŸ“š Source attribution for each answer
- âš ï¸ Escalation logging for unresolved queries

---

## ğŸ§± Architecture Overview

The assistant follows a modular pipeline:

User Query â”‚ â–¼ [main.py] â†’ Entry point, memory handling, routing â”‚ â–¼ [search.py] â†’ Vector search using embeddings â”‚ â–¼ [llm_integration.py] â†’ OpenAI GPT-4o for answer generation and summarization â”‚ â–¼ [ingest.py] â†’ Document loading and chunking â”‚ â–¼ [escalate.py] â†’ Logs unresolved queries â”‚ â–¼ [memory.json] â†’ Stores persistent Q&A history

Code

---

## ğŸ› ï¸ Setup Instructions

### 1. Clone the Repository
```bash
git clone https://github.com/PranayDolas95/Python-Project-101.git
cd Python-Project-101
2. Create a Virtual Environment
bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
3. Install Dependencies
bash
pip install -r requirements.txt
4. Add Your OpenAI API Key
Create a .env file in the root directory:

Code
OPENAI_API_KEY=your-api-key-here
â–¶ï¸ Running the Assistant
bash
python knowledge_assistant/main.py
Youâ€™ll see:

Relevance scores for each query

Detailed answers with source attribution

Follow-up suggestions

Memory-aware responses like:

â€œWhat did I ask last time?â€

â€œWhy did that happen?â€

â€œCan you continue our last discussion?â€

ğŸ“ File Structure
Code
Python-Project-101/
â”œâ”€â”€ knowledge_assistant/
â”‚   â”œâ”€â”€ main.py                 # Core logic and memory handling
â”‚   â”œâ”€â”€ ingest.py               # Document loading and chunking
â”‚   â”œâ”€â”€ search.py               # Vector search logic
â”‚   â”œâ”€â”€ llm_integration.py      # GPT-4o answer generation
â”‚   â”œâ”€â”€ escalate.py             # Escalation logging
â”‚   â”œâ”€â”€ memory.json             # Persistent memory store
â”œâ”€â”€ tickets/
â”‚   â””â”€â”€ escalations.json        # Logged unresolved queries
â”œâ”€â”€ .env                        # Your OpenAI API key (not committed)
â”œâ”€â”€ .env.example                # Safe placeholder for sharing
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # Project documentation
â”œâ”€â”€ .gitignore                  # Prevents clutter from pycache, env, etc.
ğŸ§ª Sample Queries to Test Memory
text
1. What is the projection cost?
2. What did I ask last time?
3. Why did that happen?
4. Can you continue our last discussion?
ğŸ¤ Contributing
Pull requests are welcome! For major changes, please open an issue first to discuss what youâ€™d like to change.

ğŸ“„ License
This project is licensed under the MIT License.

ğŸ™Œ Credits
Built by Harshwardhan for Pranay Dolas Powered by OpenAI GPT-4o Maintained with â¤ï¸ and Python

Code

---

Let me know if you want:
- A visual architecture diagram (I can generate one)
- A GitHub project banner or logo
- A demo GIF or video walkthrough

This README will make your project shine on GitHub â€” professional, clear, and ready for collaboration ğŸš€
