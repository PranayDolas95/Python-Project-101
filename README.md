# ðŸ§  Knowledge Assistant CLI

A modular **Retrieval-Augmented Generation (RAG)** based command-line Knowledge Assistant that answers user queries from your custom documents.  
If the assistant cannot find a confident answer, it **creates an escalation ticket**, and for each correct answer, it automatically **suggests a relevant follow-up question**.

---

## ðŸš€ Features

âœ… **Document Ingestion** â€“ Load and split large documents into searchable chunks  
âœ… **Semantic Search** â€“ Retrieve the most relevant chunks using vector similarity  
âœ… **LLM-Powered Answers** â€“ Generate concise, context-aware answers using an LLM  
âœ… **Automatic Follow-up Questions** â€“ Suggest a contextually relevant follow-up after each successful answer  
âœ… **Escalation System** â€“ Log unanswered or low-confidence queries into a ticket file for review  
âœ… **Configurable Threshold** â€“ Adjust the relevance score cutoff for fallback/escalation behavior  

---

## ðŸ—ï¸ Project Structure

knowledge-assistant/
â”‚
â”œâ”€â”€ ingest.py # Document loader and splitter
â”œâ”€â”€ search.py # Vector store creation and semantic search
â”œâ”€â”€ llm_integration.py # LLM answer generation, summarization, and follow-up
â”œâ”€â”€ escalate.py # Escalation ticket handler
â”œâ”€â”€ main.py # CLI controller and logic orchestrator
â”‚
â”œâ”€â”€ data/ # Folder containing knowledge base documents
â”œâ”€â”€ tickets/
â”‚ â””â”€â”€ escalations.json # Logged escalation tickets
â”‚
â”œâ”€â”€ requirements.txt # Dependencies list
â””â”€â”€ README.md # Project documentation

yaml
Copy code

---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/knowledge-assistant.git
cd knowledge-assistant
2. Create a Virtual Environment
bash
Copy code
python -m venv venv
source venv/bin/activate      # On Linux/Mac
venv\Scripts\activate         # On Windows
3. Install Dependencies
bash
Copy code
pip install -r requirements.txt
4. Set Environment Variables
Create a .env file or export variables manually:

bash
Copy code
RELEVANCE_THRESHOLD=1.2
OPENAI_API_KEY=your_api_key_here
5. Add Documents
Place your knowledge base files (PDFs, text, etc.) inside the data/ directory.

ðŸ§© How It Works
Document Ingestion

ingest.py loads all documents and splits them into small text chunks for efficient retrieval.

Vector Search

search.py embeds each chunk and builds a vector index.

When you ask a question, it finds the most similar chunks by semantic meaning.

Answer Generation

llm_integration.py combines the retrieved context with your question.

It uses an LLM to form a contextually aware answer.

Then, it summarizes the answer for clarity.

Follow-up Generation

After a correct answer, a relevant follow-up question is automatically generated to deepen user understanding.

Escalation

If the assistant cannot find enough relevant information (low relevance or weak LLM confidence),
a ticket is created inside tickets/escalations.json with the question and timestamp.

ðŸ§  Example Usage
bash
Copy code
$ python main.py
Knowledge Assistant ready!
Tickets logged at: /path/to/tickets/escalations.json

>> What is data encryption?
Relevance distances: [0.45, 0.52, 0.60]

Answer:
Data encryption is the process of converting readable data into coded form to prevent unauthorized access.

Follow-up:
Would you like to learn about the different types of encryption methods?
If relevance is too low:

bash
Copy code
>> What is alien signal detection?
Relevance distances: [1.78, 1.94]
I couldnâ€™t find enough information. A support ticket was created.
ðŸ§± Architecture Overview
ðŸ”¹ Modules and Responsibilities
Module	Responsibility
ingest.py	Load and split documents into chunks
search.py	Create embeddings and perform semantic search
llm_integration.py	Generate, summarize, and produce follow-up questions
escalate.py	Create structured JSON tickets for unresolved queries
main.py	User interaction loop, orchestration logic, and decision control

ðŸ§© Logic Flow
text
Copy code
User Query
   â†“
Vector Search (semantic)
   â†“
If Relevance < Threshold â†’ Keyword Fallback â†’ Escalate (ticket)
   â†“
If Relevance â‰¥ Threshold â†’ LLM Answer â†’ Summarize â†’ Generate Follow-up
   â†“
Display Answer + Follow-up
ðŸ“ Escalation Ticket Format
Example escalations.json entry:

json
Copy code
{
  "reference_id": "b7e2a3f0-92b1-45d8-9f63-d7a2a81a1a2f",
  "timestamp": "2025-10-27T14:21:36Z",
  "question": "What is quantum cloud networking?",
  "reason": "Low relevance. Insufficient knowledge."
}
ðŸ§© Customization
Feature	Description	How to Modify
Relevance Threshold	Controls when fallback or escalation triggers	Change RELEVANCE_THRESHOLD in .env
Embedding Model	Change text vectorization model	Modify create_vector_store() in search.py
LLM Provider	Use OpenAI, Anthropic, or Local LLMs	Update generate_answer() in llm_integration.py
Ticket Storage	Change log location or format	Edit escalate.py

ðŸ§ª Future Enhancements
ðŸŒ Web-based dashboard for reviewing escalations

ðŸ’¾ Persistent vector store (FAISS, Qdrant, or ChromaDB)

ðŸ” Auto-learning: add resolved tickets back to the knowledge base

ðŸ—£ï¸ Multi-turn conversation context memory

ðŸ§‘â€ðŸ’» Author
Himanshu Sapkale
ðŸ’¼ DevSecOps Engineer | Cloud Security Enthusiast
ðŸ“§ [youremail@example.com]
ðŸŒ [LinkedIn Profile or Portfolio link]

ðŸªª License
This project is licensed under the MIT License â€“ feel free to use, modify, and distribute with attribution.

ðŸ Summary
The Knowledge Assistant bridges the gap between automated document intelligence and human escalation, enabling:

Faster knowledge retrieval

Transparent fallback mechanisms

Smart contextual conversations

Itâ€™s a lightweight, extensible, and intelligent foundation for internal enterprise knowledge management systems.

pgsql
Copy code

---

Would you like me to make this README **automatically generate and update version info (e.g., build date, version number)** in the header each time you run the app?  
That can make it look like a professional maintained project.
